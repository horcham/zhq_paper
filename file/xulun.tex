\section{前言}
大量数据代表了价值。数据背后通常隐含着客观规律，如果数据量足够大的话，其规律是可以被认知和学习的，其催生了机器学习的研究方向，研究如何用数据进行建模与变现。然而，由于数据量极大，而且所涉及的算法会很复杂，通常不可能进行人为的计算，即使是用计算机进行计算，也对计算机的处理速度，内存，储存空间提出了一定的要求。另一方面，如若要进行机器学习，除了计算机硬件的要求之外，还需要软件与算法的支持，其中，算法是机器学习的核心。历史发展来看，计算机硬件，用于机器学习的软件与算法的发展是相辅相成的。

在20世纪40年代，人们开始研究人工智能，由于生物学的发展，人们模仿人类的神经元运作而提出了神经网络的原型：M-P神经元模型，并提出了激活函数的概念。在20世纪50年代到60年代，感知器算法、梯度下降法、最小二乘法等求解算法面世，而且提出了感知器，并开始应用在文字、语音、信号等领域。在20世纪60年代到70年代，神经网络算法因感知器的缺陷而衰落。在70年代到80年代，神经网络的种类变得丰富起来，涌现出BP神经网络，RBF神经网络等各种网络，并提出了深度学习的概念与卷积神经网络（CNN）和循环神经网络（RNN）的结构。90年代后，一些有别于神经网络的算法面世，如SVM，决策树，boosting与随机森林等方法，从不同的角度对机器学习算法进行丰富。在2006年，Hinton提出了解决深度学习中梯度消失问题的解决方法之后，深度学习开始爆发。2012年，ReLU激活函数的提出，进一步抑制了梯度消失的问题，并且深度学习在语音和图像方面开始有惊人的表现。2012年，在ImageNet图像识别比赛上，AlexNet通过构建一定深度的CNN夺得冠军，其性能彻底击败了SVM。需注意的是，AlexNet首次使用了ReLU激活函数，Dropout防止过拟合方法，以及GPU加速。之后，在AlexNet的结构上做优化，又提出了其他更强大的模型，如VGGNet，Inception系列，ResNet等。强化学习和迁移学习的提出，进一步增强了模型的性能。

本论文基于kaggle（全球数据科学平台）的花苗分类竞赛(Plant Seedlings Classification\footnote{\url{https://www.kaggle.com/c/plant-seedlings-classification}})中的数据集，探究传统机器学习算法（SVM，决策树，随机森林与boosting等）、深度学习算法（AlexNet，VGGNet，InceptionV3）的原理与性能，并对其尝试做优化与结合（如AlexNet+SVM等）。
